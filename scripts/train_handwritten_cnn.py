##scripts/train_handwritten_cnn.py
#!/usr/bin/env python3
"""
Train a simple CNN from scratch to classify handwritten characters (62 classes).

Input (generated by scripts/make_handwritten_dataset.py):
  data/processed/handwritten_chars/
    - images/*.png   (32x32 grayscale)
    - labels.csv     columns: path,label   (relative paths under the processed folder)

Outputs:
  models/handwritten_char_cnn/
    - model.pt
    - classes.json
  outputs/
    - train_log.csv
    - confusion_matrix.png
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

try:
    import cv2
except Exception as e:
    raise SystemExit("Missing dependency: opencv-python (cv2). Install it in your venv.") from e


class CharDataset(Dataset):
    def __init__(self, df: pd.DataFrame, classes: list[str], base_dir: Path, augment: bool = False):
        self.df = df.reset_index(drop=True)
        self.classes = classes
        self.class_to_idx = {c: i for i, c in enumerate(classes)}
        self.base_dir = base_dir
        self.augment = augment

    def __len__(self) -> int:
        return len(self.df)

    def _augment(self, img: np.ndarray) -> np.ndarray:
        # small, safe augmentations (keep it mild for handwriting)
        if np.random.rand() < 0.5:
            angle = np.random.uniform(-10, 10)
            h, w = img.shape
            M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
            img = cv2.warpAffine(
                img, M, (w, h),
                flags=cv2.INTER_LINEAR,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=255
            )
        if np.random.rand() < 0.4:
            tx = int(np.random.uniform(-2, 2))
            ty = int(np.random.uniform(-2, 2))
            M = np.float32([[1, 0, tx], [0, 1, ty]])
            h, w = img.shape
            img = cv2.warpAffine(
                img, M, (w, h),
                flags=cv2.INTER_LINEAR,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=255
            )
        if np.random.rand() < 0.3:
            k = int(np.random.choice([1, 2]))
            kernel = np.ones((k, k), np.uint8)
            if np.random.rand() < 0.5:
                img = cv2.erode(img, kernel, iterations=1)
            else:
                img = cv2.dilate(img, kernel, iterations=1)
        return img

    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        rel_path = str(row["path"])
        label = str(row["label"])

        img_path = self.base_dir / rel_path
        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise FileNotFoundError(f"Could not read image: {img_path}")

        if self.augment:
            img = self._augment(img)

        # normalize to [0,1] and invert (ink=1, background=0)
        x = img.astype(np.float32) / 255.0
        x = 1.0 - x

        x = torch.from_numpy(x).unsqueeze(0)  # [1,32,32]
        y = torch.tensor(self.class_to_idx[label], dtype=torch.long)
        return x, y


class SimpleCNN(nn.Module):
    def __init__(self, num_classes: int):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 16x16

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 8x8

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 4x4

            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.25),
            nn.Linear(256, num_classes),
        )

    def forward(self, x):
        return self.net(x)


@torch.no_grad()
def evaluate(model: nn.Module, loader: DataLoader, device: torch.device):
    model.eval()
    criterion = nn.CrossEntropyLoss()

    total = 0
    correct = 0
    losses = []
    all_true = []
    all_pred = []

    for x, y in loader:
        x = x.to(device)
        y = y.to(device)

        logits = model(x)
        loss = criterion(logits, y)
        losses.append(float(loss.item()))

        pred = torch.argmax(logits, dim=1)
        total += y.numel()
        correct += (pred == y).sum().item()

        all_true.extend(y.cpu().numpy().tolist())
        all_pred.extend(pred.cpu().numpy().tolist())

    acc = correct / max(1, total)
    return float(np.mean(losses)), float(acc), np.array(all_true), np.array(all_pred)


def plot_confusion_matrix(cm: np.ndarray, classes: list[str], out_path: Path, max_classes: int = 62):
    # Keep it readable: for 62 classes we still save it, but it will be dense.
    fig = plt.figure(figsize=(12, 12))
    ax = fig.add_subplot(111)
    ax.imshow(cm, interpolation="nearest")
    ax.set_title("Confusion Matrix (validation)")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")

    # Only label if not too huge
    if len(classes) <= max_classes:
        ax.set_xticks(np.arange(len(classes)))
        ax.set_yticks(np.arange(len(classes)))
        ax.set_xticklabels(classes, rotation=90, fontsize=6)
        ax.set_yticklabels(classes, fontsize=6)

    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data-dir", default="data/processed/handwritten_chars", help="Processed dataset folder")
    parser.add_argument("--model-dir", default="models/handwritten_char_cnn", help="Where to save model/classes")
    parser.add_argument("--out-dir", default="outputs", help="Where to save logs/plots")
    parser.add_argument("--epochs", type=int, default=20)
    parser.add_argument("--batch-size", type=int, default=64)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--val-split", type=float, default=0.2)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--cpu", action="store_true", help="Force CPU even if MPS is available")
    args = parser.parse_args()

    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    data_dir = Path(args.data_dir)
    labels_path = data_dir / "labels.csv"
    if not labels_path.exists():
        raise SystemExit(f"labels.csv not found: {labels_path}")

    df = pd.read_csv(labels_path)
    # labels.csv produced by our builder uses: filename,label,source_path
    if "filename" in df.columns and "path" not in df.columns:
        df = df.rename(columns={"filename": "path"})

    if "path" not in df.columns or "label" not in df.columns:
        raise SystemExit(f"labels.csv must contain path,label (or filename,label). Found: {list(df.columns)}")

    df["path"] = df["path"].astype(str)
    df["label"] = df["label"].astype(str)


    classes = sorted(df["label"].astype(str).unique().tolist())
    num_classes = len(classes)
    print(f"Classes: {num_classes}")

    train_df, val_df = train_test_split(
        df,
        test_size=args.val_split,
        random_state=args.seed,
        stratify=df["label"].astype(str),
    )

    train_ds = CharDataset(train_df, classes, base_dir=data_dir, augment=True)
    val_ds = CharDataset(val_df, classes, base_dir=data_dir, augment=False)

    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)

    device = torch.device("mps" if torch.backends.mps.is_available() and not args.cpu else "cpu")
    print("Device:", device)

    model = SimpleCNN(num_classes).to(device)
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    criterion = nn.CrossEntropyLoss()

    out_dir = Path(args.out_dir)
    model_dir = Path(args.model_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    model_dir.mkdir(parents=True, exist_ok=True)

    log_path = out_dir / "train_log.csv"
    best_model_path = model_dir / "model.pt"
    classes_path = model_dir / "classes.json"
    cm_path = out_dir / "confusion_matrix.png"

    best_val_acc = -1.0
    logs = []

    for epoch in range(1, args.epochs + 1):
        model.train()
        train_losses = []
        train_total = 0
        train_correct = 0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{args.epochs}")
        for x, y in pbar:
            x = x.to(device)
            y = y.to(device)

            optimizer.zero_grad(set_to_none=True)
            logits = model(x)
            loss = criterion(logits, y)
            loss.backward()
            optimizer.step()

            train_losses.append(float(loss.item()))
            pred = torch.argmax(logits, dim=1)
            train_total += y.numel()
            train_correct += (pred == y).sum().item()

            pbar.set_postfix(loss=float(np.mean(train_losses)), acc=train_correct / max(1, train_total))

        train_loss = float(np.mean(train_losses))
        train_acc = train_correct / max(1, train_total)

        val_loss, val_acc, y_true, y_pred = evaluate(model, val_loader, device)

        print(f"Epoch {epoch:02d} | train loss {train_loss:.4f} acc {train_acc:.4f} | val loss {val_loss:.4f} acc {val_acc:.4f}")

        logs.append(
            {
                "epoch": epoch,
                "train_loss": train_loss,
                "train_acc": train_acc,
                "val_loss": val_loss,
                "val_acc": val_acc,
            }
        )
        pd.DataFrame(logs).to_csv(log_path, index=False)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(
                {
                    "model_state": model.state_dict(),
                    "classes": classes,
                    "epoch": epoch,
                    "val_acc": val_acc,
                },
                best_model_path,
            )
            with open(classes_path, "w", encoding="utf-8") as f:
                json.dump(classes, f, ensure_ascii=False, indent=2)

    # confusion matrix using best checkpoint? We'll use final model state,
    # but usually it's close. If you want, we can reload best_model_path.
    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(classes)))
    plot_confusion_matrix(cm, classes, cm_path)

    print("=== Done ===")
    print("Best val acc:", best_val_acc)
    print("Saved model:", best_model_path)
    print("Saved classes:", classes_path)
    print("Log:", log_path)
    print("Confusion matrix:", cm_path)


if __name__ == "__main__":
    main()
